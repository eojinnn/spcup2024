def extract_number(filename):
    match = re.search(r'spk_(\d+)-', filename)
    if match:
        return int(match.group(1))
    else:
        return float('inf')  # 일치하는 부분이 없는 경우 맨 뒤로 정렬


# 모델 로드 함수 정의
def load_model(model_path, device):
    points = os.listdir(model_path)
    checkpoint = torch.load(model_path +'/'+ points[-1], map_location=device)
    model = TDNN(input_dim=128, num_classes=18).to(device)
    model.load_state_dict(checkpoint['model'])
    return model

model_path = "G:/SP_CUP_2024/model"
enroll_path = "G:/SP_CUP_2024/ROBOVOX_SP_CUP_2024/data/single-channel/enrollment"
test_path = "G:/SP_CUP_2024/ROBOVOX_SP_CUP_2024/data/single-channel/test"
enroll_list = "G:/SP_CUP_2024/ROBOVOX_SP_CUP_2024/data/single-channel/enrollment/annotations.txt"

enroll_dic={}
with open(enroll_list, 'r+') as file:
    content = file.read().splitlines()

for i in content:
    key, value = i.split()[0], i.split()[1]
    if key in enroll_dic:
        enroll_dic[key].append(value)
    else:
        enroll_dic[key] = [value]

model = load_model(model_path, device)
model.eval()

xvectors = {}
batch_size = 100
batch_data = []
batch_labels = []


for label, audio_files in enroll_dic.items():
    for audio_file in audio_files:
        audio, sr = librosa.load(enroll_path + audio_file,sr = 16000)
        length = num_frames * 160 + 240
        if audio.shape[0] <= length:
            shortage = length - audio.shape[0]
            audio = numpy.pad(audio, (0, shortage), 'wrap') #오디오 길이가 2초보다 짧을 때는 wrapping
        start_frame = numpy.int64(random.random()*(audio.shape[0]-length))
        audio = audio[start_frame:start_frame + length]
        inputs = numpy.stack([audio],axis=0)
    
        mfccs = extract_mfcc(inputs[0], sr=16000)
        batch_data.append(mfccs)
        batch_labels.append(label)
    print(len(batch_data))    
    if len(batch_data) > batch_size:        
        features = torch.tensor(batch_data[:batch_size], dtype=torch.float32)
        print(f"Feature batch shape: {features.size()}")
        features= features.to(device)
        _, x_vector = model(features)
        
        for i, label in enumerate(batch_labels[:batch_size]):
            if label not in xvectors:
                xvectors[label] = []
            xvectors[label].append(x_vector[i].detach().cpu().numpy())
        
        batch_data = batch_data[batch_size:]
        batch_labels = batch_labels[batch_size:]
if batch_data:
    features = torch.tensor(batch_data, dtype= torch.float32).to(device)
    print(f"Feature batch shape: {features.size()}")
    _, x_vector = model(features)

    for i, label in enumerate(batch_labels[:batch_size]):
        if label not in xvectors:
            xvectors[label] = []
        xvectors[label].append(x_vector[i].detach().cpu().numpy())

